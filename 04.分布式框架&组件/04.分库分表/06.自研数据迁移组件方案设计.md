# 1.全量数据同步

  
前提：

- 假设已经把分库分表的业务系统代码都开发好了，并且测试和验收通过了；
- 假设线上生产环境里已经创建了多个库和多表；
- 假设线上生产环境里有单库和单表，即老系统在运行中；

![[Pasted image 20240116142924.png|1500]]

此方案也称为<font color="#f79646">滚动拉取数据同步方案</font>。且全量数据同步中断可恢复。

思考：

- 历史数据为啥不是基于binlog同步呢？因为一般binlog可能被清理了，保存多久需要看具体的情况，况且，我们并没有开启~
- 历史数据同步，如果从主库同步，必然影响线上业务~

# 2.增量数据同步

>必须满足不丢失！！!

在增量同步环节，是通过Canal监听MySQL中的binlog日志，将其发送至MQ。然后定时任务消费MQ中的binlog消息时，如何保证从MQ中获取的binlog消息，一定不会丢失呢？不然的花，旧库增删改操作了，但是由于消息丢失了，导致新库中没有对应的增量数据操作，旧库和新库的数据就会不一致。

为了防止binlog消息丢失，我们引入了消息拉取和消息的提交机制。

![[Pasted image 20240116142954.png|1300]]

# 3.增量数据同步改进
  
下面的方案通过引入合并、过滤、读写队列机制提高写入效率~

![[Pasted image 20240116143011.png|1500]]

- 读写队列：添加完消费记录之后，此时并不会⻢上就到新库中，⽽是先放到⼀个写队列中，与写队列相应的，还有⼀个读队列，读队列是专⻔交给定时任务三，负责处理消息写⼊操作的。
- 数据合并：
    - 假设在我们单库⾥⾯医嘱数据1在短时间进⾏了多次操作，某天12:00:00点进⾏了⼀次新增操作，12:00:01和12:00:02的时候分别对这条数据有进⾏了两次修改操作，最后再12:00:03分时，⼜删除了这条数据。
    - 医嘱数据2在短时间内，也进⾏了多次操作，12:00:00点进⾏了⼀次新增操作，12:00:01和12:00:02分别进⾏了 两次修改操作。
    - 我们可以清晰的看到，如果直接在新库中重做这些binlog⽇志的话，会发现，对于医嘱数据1而言，依次执行了四次操作之后，新库新增的医嘱数据1，最终也会被最后⼀步删除操作给删除掉，那前三步的操作就没有任何意义了，而且还耗费性能。
    - 对于医嘱数据2而言，我们也可以只保留最后的⼀次修改操作，所以，我们可以对医嘱数据1和医嘱数据2，只保留更新时间为最新的binlog⽇志。
- 数据过滤：这⾥有个⼩细节，我们在数据合并后，⼜从合并后的binlog⽇志中获取seqId，根据seqId再到新库中查询对应的医嘱数据，然后拿着新库的医嘱数据，和旧库的binlog数据进⾏对⽐。
    - 如果新库中也能查到这条数据：
        - 那么，只有当旧库医嘱的更新时间⼤于新库的更新时间，也就是旧库的数据更新，这样才允许更新到新库中；
        - 如果当前的binlog⽇志的操作类型为删除操作，那可以不⽤对⽐更新时间，直接在新库中重做这条binlog⽇志，毕竟旧库如果要删除⼀条数据时，是不会在医嘱数据中更新修改时间的；
    - 但是，如果旧库的⼀条binlog⽇志对应的医嘱数据，在新库中没有查到：
        - 那么，如果binlog⽇志是删除操作，那就没必要在新库中重做这条⽇志了，直接过滤掉（注意：如果历史数据没有同步完成，需要延迟消费，等待历史数据同步完成了，有数据之后，再消费），新库都没有数据了，就没必要执⾏删除操作了；
        - 如果binlog⽇志的类型为修改操作，那也没必要执⾏修改操作，因为新库没数据，直接update也不⾏，我们可以将binlog的操作类型修改为新增操作，毕竟在binlog⽇志中，包含了⼀条医嘱数据的所有字段的值，⾜以满⾜新增医嘱数据需要的所有字段了。
    - 经过本次的数据过滤操作的话，⼀⽅⾯避免旧库中的那些旧数据，覆盖新库的新数据，另外⼀⽅⾯避免了那些没必要执⾏的删除和更新操作在新库执⾏。
