# 数据库优化阶段

| 优先级 | 阶段 |  |
| ---- | ---- | ---- |
| 1 | SQL优化&索引优化 |  |
| 2 | 构建缓存 |  |
| 3 | 读写分离 |  |
| 4 | 利用分区表（不推荐） | 了解内容 |
| 5 | 垂直拆分 | 复杂度比水平拆分要小 |
| 6 | 水平拆分 | 成本最高 |

**推荐资料**

* [数据库优化的几个阶段](https://www.cnblogs.com/rjzheng/p/9619855.html)
* [分库分表后如何部署上线](https://www.cnblogs.com/rjzheng/p/9597810.html)

# 高性能架构模式


## 读写分离


## 分库分表

### 垂直拆分

垂直拆分一般是按照业务和功能的维度进行拆分，把数据分别放到不同的数据库中。

![[Pasted image 20240102145506.png|450]]

**垂直分库**针对的是一个系统中对不同的业务进行拆分，根据业务维度进行数据的分离，剥离为多个数据库。比如电商网站早期，商品数据、会员数据、订单数据都是集中在一个数据库中，随着业务的发展，单库处理能力已成为瓶颈，这个时候就需要进行相关的优化，进行业务维度的拆分，分离出会员数据库、商品数据库和订单数据库等。

**垂直分表**是针对业务上的字段比较多的大表进行的（宽表呗），一般是把业务宽表中比较独立的字段，或者不常用的字段拆分到单独的数据表中。比如早期的商品表中，可能包含了商品信息、价格、库存等，可以拆分出来价格扩展表、库存扩展表等。

### 水平拆分

水平拆分是把相同的表结构分散到不同的数据库和不同的数据表中，避免访问集中的单个数据库或者单张数据表，具体的分库和分表规则，一般是通过业务主键，进行哈希取模操作。

例如，电商业务中的订单信息访问频繁，可以将订单表分散到多个数据库中，实现分库；在每个数据库中，继续进行拆分到多个数据表中，实现分表。路由策略可以使用订单ID或者用户ID，进行取模运算，路由到不同的数据库和数据表中。

![[Pasted image 20240102145807.png|550]]

### 存在问题

1. 分布式事务问题
2. 跨库关联查询问题
3. 跨库跨表的合并和排序问题
	1. 比如分页查询

1. 分库分表的维度问题
2. 唯一主键问题
3. 路由规则
4. 上线方案
	1. 停机上线
	2. 不停机上线
5. 扩容方案
	1. 停机迁移
	2. 不停机迁移

## 实现方式

### 增强驱动

### 中间件

## 解决方案

### SharedingShpere

* 垂直分表（ShardingSphere不用考虑，业务端自身解决）
* 垂直分库
* <font color="#f79646">水平分表</font>
* 水平分库

### MyCat


# 数据迁移方案


## 1_停机迁移


## 2_双写_ShardingSphere_Proxy


## 3_双写_自研组件1


## 4_双写_自研组件2

此方案来自：[分库分表扩容如何实现平滑数据迁移？ - 知乎](https://www.zhihu.com/question/447212869)

通过此文，需要明确完整的一套数据迁移方案应具备哪些能力？

* 数据同步
	* 全量同步（历史数据全量同步）：
		* <font color="#f79646">组件</font>从旧库分批查询数据，经过REHASH后批量插入到新库；
		* 另外特别需要注意的是，在全量同步期间，历史数据也会存在不断的更新。如果先开启历史数据全量同步，则刚同步完成的数据有可能不是最新的。所以这里的做法是：
			* 先开启增量数据单向同步（从旧库到新库），此时只是积压MQ消息并不会被消费；
			* 然后开启历史数据全量同步，当历史全量数据同步完成后，再开启消费MQ消息进行增量数据同步（提高全量同步效率减少积压也是关键的一环），这样来保证迁移数据过程中的数据一致。
	* 实时同步（增量数据实时同步）：增量数据同步考虑到灰度切流稳定性、容灾和可回滚能力，采用实时双向同步方案，切流过程中一旦新库出现稳定性问题或者新库出现数据一致问题，可快速回滚切回旧库，保证数据库的稳定和数据可靠。
		* 灰度切流（容灾也是通过切流实现的）
		* 被订阅数据库binlog发送至MQ，<font color="#f79646">组件</font>将消息进行过滤、合并、分组、REHASH、拆表、批量执行SQL，最后再提交offset等一系列操作。
			* 过滤循环消息：
			* 数据合并
			* UPDATE转INSERT：
	* REHASH：其实个人认为这里应该取路由策略
* 数据校验
	* 实时校验
	* 全量校验
	* 校验规则
* 数据修复


![[Pasted image 20240110181753.png|550]]


